{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01534cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the VectorStoreIndex and SimpleDirectoryReader classes from the llama_index module\n",
    "import os\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55a3b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data_dir variable is used to specify the directory from which the text data will be loaded.\n",
    "# Set the directory path where the text data is located\n",
    "data_dir = \"../chat_engine/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the indexes\n",
    "index_dict = {}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9e28f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the files in the directory\n",
    "for filename in os.listdir(data_dir):\n",
    "    file_path = os.path.join(data_dir, filename)\n",
    "    \n",
    "    # Create a separate index for each file\n",
    "    reader = SimpleDirectoryReader(input_dir=file_path)\n",
    "    data = reader.load_data()\n",
    "    index = VectorStoreIndex.from_documents(data)\n",
    "    index_dict[filename] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eded2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create separate chat engines for each index\n",
    "chat_engine_dict = {}\n",
    "for filename, index in index_dict.items():\n",
    "    chat_engine = index.as_chat_engine(chat_mode='react', verbose=True)\n",
    "    chat_engine_dict[filename] = chat_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701918fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display all available engines\n",
    "print(\"Available engines:\")\n",
    "for i, filename in enumerate(chat_engine_dict.keys()):\n",
    "    print(f\"{i+1}. {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7789258",
   "metadata": {},
   "source": [
    "**Available engines:**\n",
    "1. CHAPTER I.txt\n",
    "2. CHAPTER II.txt\n",
    "3. CHAPTER III.txt\n",
    "4. CHAPTER IV.txt\n",
    "5. CHAPTER V.txt\n",
    "6. CHAPTER VI.txt\n",
    "\n",
    "This allows the user to see a numbered list of available engines and select the desired engine by entering the corresponding number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b37403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt user to select the engine\n",
    "selected_index = int(input(\"Select the engine (1, 2, 3, ...): \"))\n",
    "selected_filename = list(chat_engine_dict.keys())[selected_index - 1]\n",
    "selected_chat_engine = chat_engine_dict[selected_filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1ba996",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt user to enter the question\n",
    "question = input(\"Enter your question: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e95b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the selected chat engine\n",
    "response = selected_chat_engine.chat(question)\n",
    "print(f\"Response from {selected_filename}: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
